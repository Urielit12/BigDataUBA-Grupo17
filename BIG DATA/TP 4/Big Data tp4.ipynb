{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62cf0d65-7e70-422c-bd77-2d284e3ff9e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'usu_individual_T104.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m----> 6\u001b[0m df_2004 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musu_individual_T104.dta\u001b[39m\u001b[38;5;124m'\u001b[39m, convert_categoricals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m df_2024 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musu_individual_T124.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m df_2004\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df_2004\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mupper()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1683\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1682\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1175\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1188\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1182\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1186\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[1;32m-> 1188\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1191\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1192\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1193\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1194\u001b[0m )\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'usu_individual_T104.dta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "df_2004 = pd.read_stata('usu_individual_T104.dta', convert_categoricals=False)\n",
    "df_2024 = pd.read_excel('usu_individual_T124.xlsx')\n",
    "\n",
    "df_2004.columns = df_2004.columns.str.upper()\n",
    "df_2024.columns = df_2024.columns.str.upper()\n",
    "columnas_comunes = df_2004.columns.intersection(df_2024.columns)\n",
    "\n",
    "df_2004_filtrado = df_2004[columnas_comunes]\n",
    "df_2024_filtrado = df_2024[columnas_comunes]\n",
    "df_combinado = pd.concat([df_2004_filtrado, df_2024_filtrado], ignore_index=True)\n",
    "\n",
    "df_eph_nea = df_combinado[df_combinado['REGION'] == 41].copy()\n",
    "\n",
    "# Variable EDAD2\n",
    "if 'CH06' in df_eph_nea.columns:\n",
    "    df_eph_nea['EDAD2'] = np.square(df_eph_nea['CH06'])\n",
    "    print(\"Variable 'edad2' añadida exitosamente.\")\n",
    "else:\n",
    "    print(\"No se encontró la columna 'CH06'.\")\n",
    "\n",
    "# Variable EDUC\n",
    "def calcular_educ(row):\n",
    "    if row['CH10'] == 1:\n",
    "        if row['CH14'] in [98, 99]:\n",
    "            return 6\n",
    "        if row['CH12'] == 1:\n",
    "            return 0\n",
    "        elif row['CH12'] == 2:\n",
    "            return row['CH14']\n",
    "        elif row['CH12'] == 3:\n",
    "            return row['CH14']\n",
    "        elif row['CH12'] == 4:\n",
    "            return 6 + row['CH14']\n",
    "        elif row['CH12'] == 5:\n",
    "            return 9 + row['CH14']\n",
    "        elif row['CH12'] == 6:\n",
    "            return 12 + row['CH14']\n",
    "        elif row['CH12'] == 7:\n",
    "            return 12 + row['CH14']\n",
    "        elif row['CH12'] == 8:\n",
    "            return 17 + row['CH14']\n",
    "        elif row['CH12'] == 9:\n",
    "            return row['CH14']\n",
    "        else:\n",
    "            return 0\n",
    "    elif row['CH10'] == 2:\n",
    "        if row['CH13'] == 1:\n",
    "            if row['CH14'] in [98, 99]:\n",
    "                return 6\n",
    "            elif row['CH12'] == 1:\n",
    "                return 0\n",
    "            elif row['CH12'] == 2:\n",
    "                return 6\n",
    "            elif row['CH12'] == 3:\n",
    "                return 9\n",
    "            elif row['CH12'] == 4:\n",
    "                return 12\n",
    "            elif row['CH12'] == 5:\n",
    "                return 12\n",
    "            elif row['CH12'] == 6:\n",
    "                return 15\n",
    "            elif row['CH12'] == 7:\n",
    "                return 17\n",
    "            elif row['CH12'] == 8:\n",
    "                return 18\n",
    "            elif row['CH12'] == 9:\n",
    "                return 6\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CH13'] == 2:\n",
    "            if row['CH14'] in [98, 99]:\n",
    "                return 6\n",
    "            elif row['CH12'] == 1:\n",
    "                return 0\n",
    "            elif row['CH12'] == 2:\n",
    "                return row['CH14']\n",
    "            elif row['CH12'] == 3:\n",
    "                return row['CH14']\n",
    "            elif row['CH12'] == 4:\n",
    "                return 6 + row['CH14']\n",
    "            elif row['CH12'] == 5:\n",
    "                return 9 + row['CH14']\n",
    "            elif row['CH12'] == 6:\n",
    "                return 12 + row['CH14']\n",
    "            elif row['CH12'] == 7:\n",
    "                return 12 + row['CH14']\n",
    "            elif row['CH12'] == 8:\n",
    "                return 17 + row['CH14']\n",
    "            elif row['CH12'] == 9:\n",
    "                return row['CH14']\n",
    "            else:\n",
    "                return 0\n",
    "    elif row['CH10'] == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for col in ['CH10', 'CH12', 'CH13', 'CH14']:\n",
    "    if col in df_eph_nea.columns:\n",
    "        df_eph_nea[col] = pd.to_numeric(df_eph_nea[col], errors='coerce')\n",
    "\n",
    "df_eph_nea['EDUC'] = df_eph_nea.apply(calcular_educ, axis=1)\n",
    "print(\"Variable 'educ' añadida exitosamente.\")\n",
    "\n",
    "# Variable SALARIO_SEMANAL\n",
    "SMVM2004 = 350\n",
    "SMVM2024 = 202800\n",
    "pp = round(SMVM2024 / SMVM2004, 2)\n",
    "\n",
    "if 'ANO4' in df_eph_nea.columns and 'ESTADO' in df_eph_nea.columns and 'P21' in df_eph_nea.columns:\n",
    "    condiciones_2004 = (df_eph_nea['ANO4'] == 2004) & (df_eph_nea['ESTADO'] == 1) & (df_eph_nea['P21'] > 0)\n",
    "    condiciones_2024 = (df_eph_nea['ANO4'] == 2024) & (df_eph_nea['ESTADO'] == 1) & (df_eph_nea['P21'] > 0)\n",
    "\n",
    "    df_eph_nea.loc[condiciones_2004, 'SALARIO_SEMANAL'] = ((df_eph_nea.loc[condiciones_2004, 'P21'] * pp) / 21.65) * 5\n",
    "    df_eph_nea.loc[condiciones_2024, 'SALARIO_SEMANAL'] = (df_eph_nea.loc[condiciones_2024, 'P21'] / 21.65) * 5\n",
    "    print(\"Variable 'salario_semanal' añadida exitosamente.\")\n",
    "else:\n",
    "    print(\"Faltan columnas necesarias para calcular 'salario_semanal'.\")\n",
    "\n",
    "# Variable HORASTRAB\n",
    "variables_a_limpiar = ['PP3E_TOT', 'PP3F_TOT']\n",
    "for var in variables_a_limpiar:\n",
    "    if var in df_eph_nea.columns:\n",
    "        df_eph_nea[var] = df_eph_nea[var].replace([99, 999, 9999], np.nan)\n",
    "\n",
    "if all(col in df_eph_nea.columns for col in variables_a_limpiar):\n",
    "    df_eph_nea['HORASTRAB'] = df_eph_nea['PP3E_TOT'] + df_eph_nea['PP3F_TOT']\n",
    "    print(\"Variable 'horastrab' añadida exitosamente.\")\n",
    "else:\n",
    "    print(\"Faltan columnas necesarias para calcular 'horastrab'.\")\n",
    "\n",
    "df_eph_nea.to_excel('EPH_NEA_2004_2024.xlsx', index=False)\n",
    "print(\"Archivo final guardado con todas las variables añadidas.\")\n",
    "\n",
    "respondieron = df_eph_nea[df_eph_nea['ESTADO'].notna() & (df_eph_nea['ESTADO'] != 0)]\n",
    "norespondieron = df_eph_nea[(df_eph_nea['ESTADO'].isna()) | (df_eph_nea['ESTADO'] == 0)]\n",
    "\n",
    "respondieron.to_excel('respondieron.xlsx', index=False)\n",
    "norespondieron.to_excel('norespondieron.xlsx', index=False)\n",
    "\n",
    "respondieron['P21'] = pd.to_numeric(respondieron['P21'], errors='coerce')\n",
    "respondieron = respondieron[respondieron['P21'] >= 0]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Variables relevantes\n",
    "variables = ['CH06', 'EDAD2', 'EDUC', 'P21', 'SALARIO_SEMANAL', 'HORASTRAB', 'ESTADO', 'CH04', 'PP04A', 'PP03D']\n",
    "columnas = ['constante'] + variables\n",
    "\n",
    "# Listas para conjuntos combinados\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for anio in [2004, 2024]:\n",
    "    df_anio = respondieron[respondieron['ANO4'] == anio]\n",
    "    y = (df_anio['ESTADO'] == 2).astype(int)  # Variable target\n",
    "\n",
    "    X_df = df_anio[variables].copy()\n",
    "    X_df.insert(0, 'constante', 1)\n",
    "\n",
    "    data = pd.concat([X_df, y.rename('target')], axis=1).dropna(subset=['target'])\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.3, random_state=444)\n",
    "\n",
    "    # Guardar para conjuntos combinados\n",
    "    train_list.append(train)\n",
    "    test_list.append(test)\n",
    "\n",
    "    # Análisis de diferencia de medias\n",
    "    tabla_dif = pd.DataFrame(index=columnas)\n",
    "\n",
    "    for var in columnas:\n",
    "        train_valid = train[[var]].dropna()\n",
    "        test_valid = test[[var]].dropna()\n",
    "\n",
    "        tabla_dif.loc[var, 'N train'] = train_valid.shape[0]\n",
    "        tabla_dif.loc[var, 'Mean train'] = train_valid[var].mean()\n",
    "        tabla_dif.loc[var, 'sd train'] = train_valid[var].std()\n",
    "\n",
    "        tabla_dif.loc[var, 'N test'] = test_valid.shape[0]\n",
    "        tabla_dif.loc[var, 'Mean test'] = test_valid[var].mean()\n",
    "        tabla_dif.loc[var, 'sd test'] = test_valid[var].std()\n",
    "\n",
    "        if len(train_valid[var]) > 1 and len(test_valid[var]) > 1:\n",
    "            t_test = stats.ttest_ind(train_valid[var], test_valid[var], equal_var=False, nan_policy='omit')\n",
    "            tabla_dif.loc[var, 't-test'] = t_test.statistic\n",
    "            tabla_dif.loc[var, 'p-value'] = t_test.pvalue\n",
    "        else:\n",
    "            tabla_dif.loc[var, 't-test'] = None\n",
    "            tabla_dif.loc[var, 'p-value'] = None\n",
    "\n",
    "    columnas_a_redondear = ['Mean train', 'Mean test', 'sd train', 'sd test', 't-test', 'p-value']\n",
    "    tabla_dif[columnas_a_redondear] = tabla_dif[columnas_a_redondear].round(2)\n",
    "\n",
    "    tabla_dif.to_excel(f'Tabla_diferencia_de_medias_{anio}.xlsx')\n",
    "    print(f\"Exportado tabla de diferencia de medias para el año {anio}\")\n",
    "\n",
    "# Guardar conjuntos combinados\n",
    "train_combined = pd.concat(train_list).reset_index(drop=True)\n",
    "test_combined = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "train_combined.to_excel(\"train_combinado.xlsx\", index=False)\n",
    "test_combined.to_excel(\"test_combinado.xlsx\", index=False)\n",
    "print(\"Conjuntos combinados guardados exitosamente.\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "ocupados = train_combined[\n",
    "    (train_combined['ESTADO'] == 1) &\n",
    "    (train_combined['SALARIO_SEMANAL'].notnull()) &\n",
    "    (train_combined['CH04'].notnull()) &  \n",
    "    (train_combined['CH06'].notnull()) &  \n",
    "    (train_combined['EDAD2'].notnull()) &\n",
    "    (train_combined['EDUC'].notnull()) &\n",
    "    (train_combined['PP04A'].notnull()) &\n",
    "    (train_combined['PP03D'].notnull())\n",
    "].copy()\n",
    "\n",
    "ocupados['mujer'] = (ocupados['CH04'] == 2).astype(int)\n",
    "\n",
    "modelos = {\n",
    "    'Modelo 1': ['CH06'],\n",
    "    'Modelo 2': ['CH06', 'EDAD2'],\n",
    "    'Modelo 3': ['CH06', 'EDAD2', 'EDUC'],\n",
    "    'Modelo 4': ['CH06', 'EDAD2', 'EDUC', 'mujer'],\n",
    "    'Modelo 5': ['CH06', 'EDAD2', 'EDUC', 'mujer', 'PP04A', 'PP03D']\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nombre, vars_indep in modelos.items():\n",
    "    X = ocupados[vars_indep]\n",
    "    X = sm.add_constant(X)\n",
    "    y = ocupados['SALARIO_SEMANAL']\n",
    "    \n",
    "    modelo = sm.OLS(y, X).fit()\n",
    "    resultados[nombre] = modelo\n",
    "\n",
    "tabla_resultados = pd.DataFrame()\n",
    "\n",
    "for nombre, modelo in resultados.items():\n",
    "    resumen = pd.DataFrame({\n",
    "        nombre: [\n",
    "            f\"{coef:.3f}\" + (\n",
    "                \"***\" if pval < 0.001 else \"**\" if pval < 0.05 else \"*\" if pval < 0.1 else \"\"\n",
    "            ) + f\"\\n({se:.2f})\"\n",
    "            for coef, se, pval in zip(modelo.params, modelo.bse, modelo.pvalues)\n",
    "        ]\n",
    "    }, index=modelo.params.index)\n",
    "\n",
    "    resumen.loc['R2'] = f\"{modelo.rsquared:.3f}\"\n",
    "    resumen.loc['N (obs)'] = int(modelo.nobs)\n",
    "    tabla_resultados = pd.concat([tabla_resultados, resumen], axis=1)\n",
    "\n",
    "print(\"Tabla 2\\n\")\n",
    "print(tabla_resultados)\n",
    "\n",
    "\n",
    "test_ocupados = test_combined[\n",
    "    (test_combined['ESTADO'] == 1) &\n",
    "    (test_combined[['SALARIO_SEMANAL', 'CH06', 'EDAD2',\n",
    "     'EDUC', 'PP04A', 'PP03D']].notnull().all(axis=1))\n",
    "].copy()\n",
    "test_ocupados['mujer'] = (test_ocupados['CH04'] == 2).astype(int)\n",
    "\n",
    "modelos = {\n",
    "    'Modelo 1': ['CH06'],\n",
    "    'Modelo 2': ['CH06', 'EDAD2'],\n",
    "    'Modelo 3': ['CH06', 'EDAD2', 'EDUC'],\n",
    "    'Modelo 4': ['CH06', 'EDAD2', 'EDUC', 'mujer'],\n",
    "    'Modelo 5': ['CH06', 'EDAD2', 'EDUC', 'mujer', 'PP04A', 'PP03D']\n",
    "}\n",
    "resultados = {'MSE': {}, 'RMSE': {}, 'MAE': {}}\n",
    "for modelo, vars_indep in modelos.items():\n",
    "\n",
    "    x = test_ocupados[vars_indep]\n",
    "    y = test_ocupados['SALARIO_SEMANAL']\n",
    "\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(x, y)\n",
    "\n",
    "    y_pred = lreg.predict(x)\n",
    "\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "    resultados['MSE'][modelo] = round(mse, 2)\n",
    "    resultados['RMSE'][modelo] = round(rmse, 2)\n",
    "    resultados['MAE'][modelo] = round(mae, 2)\n",
    "\n",
    "tabla_resultados = pd.DataFrame(resultados)\n",
    "# Transponer para tener métricas como filas\n",
    "tabla_resultados = tabla_resultados.T\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"\\nTabla de resultados (métricas por fila):\")\n",
    "print(tabla_resultados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
